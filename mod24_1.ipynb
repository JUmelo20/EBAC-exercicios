{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19aaa32-9eef-4b63-abe7-f124795c6b94",
   "metadata": {},
   "source": [
    "## 1.  Cite 5 diferenças entre o Random Forest e o AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54c3d9-5f26-459e-bc1d-1f98283b9599",
   "metadata": {},
   "source": [
    "**Algoritmos base:** Random Forest é baseado em um conjunto de árvores de decisão independentes, enquanto o AdaBoost é baseado em um conjunto de classificadores fracos, geralmente árvores de decisão simples.\n",
    "\n",
    "**Peso das amostras:** No Random Forest, cada árvore é treinada em um subconjunto aleatório dos dados de treinamento, sem considerar os pesos das amostras. No AdaBoost, cada classificador fraco é treinado com maior ênfase nas amostras classificadas incorretamente pelos classificadores anteriores, ajustando os pesos das amostras a cada iteração.\n",
    "\n",
    "**Processo de treinamento:** Random Forest treina as árvores independentemente, de forma paralela, enquanto o AdaBoost treina os classificadores fracos sequencialmente, ajustando os pesos das amostras a cada iteração.\n",
    "\n",
    "**Ponderação dos classificadores:** Em Random Forest, cada árvore tem o mesmo peso na previsão final. No AdaBoost, os classificadores fracos são ponderados com base em sua taxa de erro durante o treinamento, onde classificadores com menor taxa de erro têm maior peso na previsão final.\n",
    "\n",
    "**Sensibilidade ao ruído:** Random Forest é menos sensível ao ruído nos dados de treinamento, pois as árvores individuais são treinadas em subconjuntos aleatórios dos dados. O AdaBoost pode ser mais sensível ao ruído, pois ajusta os pesos das amostras em cada iteração."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ceaef-34bb-49e1-a376-39075e2523e6",
   "metadata": {},
   "source": [
    "## 2. Exemplo do AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c2ba7c-6abe-4fc9-9b56-4be6da3cc768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar o conjunto de dados iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o classificador AdaBoost\n",
    "adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Treinar o classificador\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia das previsões\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0182b-c582-4754-a3a5-0a97ab400e11",
   "metadata": {},
   "source": [
    "## 3. Cite 5 Hyperparametros importantes no AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e9d21-e3a6-4e50-82bb-811ddf76b0eb",
   "metadata": {},
   "source": [
    "**base_estimator:** O classificador fraco usado como base para construir o conjunto. Geralmente, árvores de decisão são usadas como classificadores fracos padrão.\n",
    "\n",
    "**n_estimators:** O número de classificadores fracos no conjunto.\n",
    "\n",
    "**learning_rate:** Controla a contribuição de cada classificador fraco no conjunto. Valores menores reduzem a influência de cada classificador fraco e requerem mais estimadores para atingir um desempenho semelhante.\n",
    "\n",
    "**algorithm:** O algoritmo usado para ajustar os pesos das amostras. Pode ser \"SAMME\" ou \"SAMME.R\". \"SAMME.R\" é recomendado, pois permite estimativas de probabilidade.\n",
    "\n",
    "**random_state:** O estado aleatório para garantir a reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c1f32-1270-4bab-842a-4cb72ec47441",
   "metadata": {},
   "source": [
    "## 4.  Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eda1aa0b-2078-444e-bd38-ac44b83ddbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros:\n",
      "{'learning_rate': 0.5, 'n_estimators': 50}\n",
      "Melhor pontuação:\n",
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Carregar o conjunto de dados iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Criar o classificador AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "# Definir os hiperparâmetros para ajustar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Realizar a busca de hiperparâmetros utilizando validação cruzada\n",
    "grid_search = GridSearchCV(adaboost, param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Exibir a melhor pontuação alcançada durante a busca de hiperparâmetros\n",
    "print(\"Melhor pontuação:\")\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4d088-f4ee-4252-9641-5c8c9aaa007a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
